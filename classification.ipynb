{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sklearn.model_selection as sk_model_selection\n",
    "import sklearn.preprocessing as sk_preprocessing\n",
    "import sklearn.metrics as sk_metrics\n",
    "import sklearn.neural_network as sk_nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './harth'\n",
    "\n",
    "files = os.listdir(data_dir)\n",
    "\n",
    "concat = pd.DataFrame()\n",
    "\n",
    "for root, _, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        new = pd.read_csv(os.path.join(root, file), index_col = 'timestamp')\n",
    "        file_name = os.path.splitext(file)[0]\n",
    "        new['file_name'] = file_name\n",
    "        concat = pd.concat([concat, new])\n",
    "label = concat['label']\n",
    "#concat.drop(labels = ['index', 'Unnamed: 0'], axis = 'columns', inplace = True)\n",
    "concat.drop(labels = ['index'], axis = 'columns', inplace = True)\n",
    "concat.reset_index(inplace = True)\n",
    "concat['timestamp'] = pd.to_datetime(concat['timestamp']).apply(lambda x: x.timestamp())\n",
    "time = concat['timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          6\n",
      "1          6\n",
      "2          6\n",
      "3          6\n",
      "4          6\n",
      "          ..\n",
      "6461323    3\n",
      "6461324    3\n",
      "6461325    3\n",
      "6461326    3\n",
      "6461327    3\n",
      "Name: label, Length: 6461328, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thela\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:697: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "#X = concat.drop(columns = ['timestamp', 'label', 'file_name']).dropna()\n",
    "#y = concat.loc[X.index, 'label']\n",
    "X = concat[['timestamp', 'back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y', 'thigh_z']]\n",
    "y = concat['label']\n",
    "print(y)\n",
    "scaler = sk_preprocessing.MinMaxScaler(feature_range = (-1,1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sk_model_selection.train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlp_classifier = sk_nn.MLPClassifier(hidden_layer_sizes=(64, 64), activation='relu', max_iter=1000)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp_classifier.predict(X_test)\n",
    "\n",
    "accuracy = sk_metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Test accuracy: {:0.2f}'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8]\n",
      "   Class     TP   FP   FN     TN\n",
      "0      1  13791  557  369  12813\n",
      "1      2   4359   32   72  23067\n",
      "2      3    104   72  297  27057\n",
      "3      4    535   70  113  26812\n",
      "4      5    446  130   48  26906\n",
      "5      6   1304  215  150  25861\n",
      "6      7   2587    4   19  24920\n",
      "7      8   3317    7   19  24187\n"
     ]
    }
   ],
   "source": [
    "cm = sk_metrics.confusion_matrix(y_test, y_pred)\n",
    "results_df = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred})\n",
    "\n",
    "def categorize_prediction(row):\n",
    "    if row['y_test'] == cls and row['y_pred'] == cls:\n",
    "        return 'TP'\n",
    "    elif row['y_test'] != cls and row['y_pred'] == cls:\n",
    "        return 'FP'\n",
    "    elif row['y_test'] == cls and row['y_pred'] != cls:\n",
    "        return 'FN'\n",
    "    else:\n",
    "        return 'TN'\n",
    "results_df['category'] = results_df.apply(categorize_prediction, axis=1)\n",
    "\n",
    "summary = []\n",
    "classes = sorted(set(y))\n",
    "print(classes)\n",
    "for cls in classes:\n",
    "    tp = ((results_df['y_test'] == cls) & (results_df['y_pred'] == cls)).sum()\n",
    "    fp = ((results_df['y_test'] != cls) & (results_df['y_pred'] == cls)).sum()\n",
    "    fn = ((results_df['y_test'] == cls) & (results_df['y_pred'] != cls)).sum()\n",
    "    tn = ((results_df['y_test'] != cls) & (results_df['y_pred'] != cls)).sum()\n",
    "    summary.append({'Label': cls, 'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn})\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# Display the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plotting bars\n",
    "bar_width = 0.2\n",
    "index = summary_df['Label']\n",
    "\n",
    "bar1 = plt.bar(index, summary_df['TP'], bar_width, label='True Positives')\n",
    "bar2 = plt.bar(index + bar_width, summary_df['FP'], bar_width, label='False Positives')\n",
    "bar3 = plt.bar(index + 2 * bar_width, summary_df['FN'], bar_width, label='False Negatives')\n",
    "bar4 = plt.bar(index + 3 * bar_width, summary_df['TN'], bar_width, label='True Negatives')\n",
    "\n",
    "# Add labels\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('True Positives, False Positives, False Negatives, and True Negatives by Class')\n",
    "plt.xticks(index + bar_width, summary_df['Class'])\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
